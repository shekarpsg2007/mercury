package com.humedica.mercury.etl.athena.util

import com.humedica.mercury.etl.core.engine.EntitySource
import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.functions._
import org.apache.spark.sql.expressions.Window
import com.humedica.mercury.etl.core.engine.Constants._
import com.humedica.mercury.etl.core.engine.Functions._


class UtilDedupedAppointment (config: Map[String, String]) extends EntitySource(config: Map[String, String]) {

  cacheMe = true
  columns=List("APPMT_SCHEDULED_DATETIME_AST", "APPOINTMENT_CANCEL_REASON", "APPOINTMENT_CANCELLED_DATETIME",
    "APPOINTMENT_CHECK_IN_DATETIME", "APPOINTMENT_CHECK_OUT_DATETIME", "APPOINTMENT_CREATED_BY",
    "APPOINTMENT_CREATED_DATETIME", "APPOINTMENT_DATE", "APPOINTMENT_DELETED_BY", "APPOINTMENT_DELETED_DATETIME",
    "APPOINTMENT_DURATION", "APPOINTMENT_FROZEN_REASON", "APPOINTMENT_ID", "APPOINTMENT_SCHEDULED_DATETIME",
    "APPOINTMENT_STARTTIME", "APPOINTMENT_STATUS", "APPOINTMENT_TYPE_BLOCK_ID", "APPOINTMENT_TYPE_DURATION",
    "APPOINTMENT_TYPE_ID", "APPOINTMENT_TYPE", "CANCELLED_BY", "CHECKED_IN_BY", "CHECKED_OUT_BY", "CLAIM_ID",
    "COLLECTIONS_AMOUNT_COLLECTED", "COLLECTIONS_AMOUNT", "CONTEXT_ID", "CONTEXT_NAME", "CONTEXT_PARENTCONTEXTID",
    "CYCLE_TIME", "DEPARTMENT_ID", "FAMILY_COLLECTION_COLLECTED", "FAMILY_OUTSTANDING_COLLECTED", "FILEID",
    "FROZENYN", "NO_CHARGE_ENTRY_REASON", "NO_CHARGE_ENTRY_SIGN_OFF", "PARENT_APPOINTMENT_ID",
    "PATIENT_FAMILY_COLLECTION_AMT", "PATIENT_FAMILY_OUTSTANDING_AMT", "PATIENT_ID", "PATIENT_OUTSTANDING_AMOUNT",
    "PATIENT_OUTSTANDING_COLLECTED", "PATIENT_OUTSTANDING_PMT_CHOICE", "PATIENT_UNAPPLIED_AMOUNT",
    "PATIENT_UNAPPLIED_COLLECTED", "PRIMARY_PATIENT_INSURANCE_ID", "PROVIDER_ID", "REFERRAL_AUTH_ID",
    "REFERRING_PROVIDER_ID", "RESCHEDULED_APPOINTMENT_ID", "RESCHEDULED_BY", "RESCHEDULED_DATETIME", "SCHEDULED_BY",
    "SCHEDULING_PROVIDER", "SCHEDULING_TEMPLATE_ID", "SECONDARY_PATIENT_INSURANCE_ID", "START_CHECK_IN_DATETIME",
    "STOP_SIGN_OFF_DATETIME", "SUGGESTED_OVERBOOKING")

  tables = List("appointment",
    "fileExtractDates:athena.util.UtilFileIdDates",
    "pat:athena.util.UtilSplitPatient")

  columnSelect = Map(
    "appointment" -> List("APPMT_SCHEDULED_DATETIME_AST", "APPOINTMENT_CANCEL_REASON", "APPOINTMENT_CANCELLED_DATETIME",
      "APPOINTMENT_CHECK_IN_DATETIME", "APPOINTMENT_CHECK_OUT_DATETIME", "APPOINTMENT_CREATED_BY",
      "APPOINTMENT_CREATED_DATETIME", "APPOINTMENT_DATE", "APPOINTMENT_DELETED_BY", "APPOINTMENT_DELETED_DATETIME",
      "APPOINTMENT_DURATION", "APPOINTMENT_FROZEN_REASON", "APPOINTMENT_ID", "APPOINTMENT_SCHEDULED_DATETIME",
      "APPOINTMENT_STARTTIME", "APPOINTMENT_STATUS", "APPOINTMENT_TYPE_BLOCK_ID", "APPOINTMENT_TYPE_DURATION",
      "APPOINTMENT_TYPE_ID", "APPOINTMENT_TYPE", "CANCELLED_BY", "CHECKED_IN_BY", "CHECKED_OUT_BY", "CLAIM_ID",
      "COLLECTIONS_AMOUNT_COLLECTED", "COLLECTIONS_AMOUNT", "CONTEXT_ID", "CONTEXT_NAME", "CONTEXT_PARENTCONTEXTID",
      "CYCLE_TIME", "DEPARTMENT_ID", "FAMILY_COLLECTION_COLLECTED", "FAMILY_OUTSTANDING_COLLECTED", "FILEID", "FROZENYN",
      "NO_CHARGE_ENTRY_REASON", "NO_CHARGE_ENTRY_SIGN_OFF", "PARENT_APPOINTMENT_ID", "PATIENT_FAMILY_COLLECTION_AMT",
      "PATIENT_FAMILY_OUTSTANDING_AMT", "PATIENT_ID", "PATIENT_OUTSTANDING_AMOUNT", "PATIENT_OUTSTANDING_COLLECTED",
      "PATIENT_OUTSTANDING_PMT_CHOICE", "PATIENT_UNAPPLIED_AMOUNT", "PATIENT_UNAPPLIED_COLLECTED",
      "PRIMARY_PATIENT_INSURANCE_ID", "PROVIDER_ID", "REFERRAL_AUTH_ID", "REFERRING_PROVIDER_ID",
      "RESCHEDULED_APPOINTMENT_ID", "RESCHEDULED_BY", "RESCHEDULED_DATETIME", "SCHEDULED_BY", "SCHEDULING_PROVIDER",
      "SCHEDULING_TEMPLATE_ID", "SECONDARY_PATIENT_INSURANCE_ID", "START_CHECK_IN_DATETIME", "STOP_SIGN_OFF_DATETIME",
      "SUGGESTED_OVERBOOKING"),
    "fileExtractDates" -> List("FILEID","FILEDATE"),
    "pat" -> List("PATIENT_ID")
  )


  join = (dfs: Map[String, DataFrame]) => {
    val patJoinType = new UtilSplitTable(config).patprovJoinType
    dfs("appointment")
      .join(dfs("fileExtractDates"), Seq("FILEID"), "left_outer")
      .join(dfs("pat"), Seq("PATIENT_ID"), patJoinType)
  }


  afterJoin = (df: DataFrame) => {
    val groups = Window.partitionBy(df("APPOINTMENT_ID")).orderBy(df("FILEDATE").desc_nulls_last,df("FILEID").desc_nulls_last)
    df.withColumn("dedupe_row", row_number.over(groups))
      .filter("dedupe_row=1 and APPOINTMENT_DELETED_DATETIME is null")
  }


}

// test
//  val a = new UtilDedupedAppointment(cfg); val o = build(a); o.count

